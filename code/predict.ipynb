{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "FatuRxB5uN-i"
   },
   "outputs": [],
   "source": [
    "ROOT='/content/drive/My Drive/dl/推荐评论/'\n",
    "BERT_ROOT='/content/drive/My Drive/dl/google-quest-challenge/pretrained-bert-models-for-pytorch/新建文件夹/bert-base-chinese/'\n",
    "BERT_TOK_ROOT='/content/drive/My Drive/dl/google-quest-challenge/pretrained-bert-models-for-pytorch/bert-base-chinese-vocab.txt'\n",
    "MAX_LEN=22"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "u5WqadHPu6D5",
    "outputId": "16c66385-e9a3-4515-b57a-84c6fa443fbe"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pytorch_pretrained_bert\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d7/e0/c08d5553b89973d9a240605b9c12404bcf8227590de62bae27acbcfe076b/pytorch_pretrained_bert-0.6.2-py3-none-any.whl (123kB)\n",
      "\r",
      "\u001b[K     |██▋                             | 10kB 25.7MB/s eta 0:00:01\r",
      "\u001b[K     |█████▎                          | 20kB 28.7MB/s eta 0:00:01\r",
      "\u001b[K     |████████                        | 30kB 34.6MB/s eta 0:00:01\r",
      "\u001b[K     |██████████▋                     | 40kB 38.7MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████▎                  | 51kB 27.9MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████▉                | 61kB 31.1MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████▌             | 71kB 23.7MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████▏          | 81kB 25.4MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████▉        | 92kB 27.4MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████████▌     | 102kB 24.6MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████████████▏  | 112kB 24.6MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████████████▊| 122kB 24.6MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████████████| 133kB 24.6MB/s \n",
      "\u001b[?25hRequirement already satisfied: boto3 in /usr/local/lib/python3.6/dist-packages (from pytorch_pretrained_bert) (1.11.15)\n",
      "Requirement already satisfied: torch>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from pytorch_pretrained_bert) (1.4.0)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from pytorch_pretrained_bert) (1.17.5)\n",
      "Requirement already satisfied: regex in /usr/local/lib/python3.6/dist-packages (from pytorch_pretrained_bert) (2019.12.20)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from pytorch_pretrained_bert) (4.28.1)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from pytorch_pretrained_bert) (2.21.0)\n",
      "Requirement already satisfied: botocore<1.15.0,>=1.14.15 in /usr/local/lib/python3.6/dist-packages (from boto3->pytorch_pretrained_bert) (1.14.15)\n",
      "Requirement already satisfied: s3transfer<0.4.0,>=0.3.0 in /usr/local/lib/python3.6/dist-packages (from boto3->pytorch_pretrained_bert) (0.3.3)\n",
      "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->pytorch_pretrained_bert) (0.9.4)\n",
      "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch_pretrained_bert) (1.24.3)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch_pretrained_bert) (2.8)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch_pretrained_bert) (2019.11.28)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch_pretrained_bert) (3.0.4)\n",
      "Requirement already satisfied: docutils<0.16,>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore<1.15.0,>=1.14.15->boto3->pytorch_pretrained_bert) (0.15.2)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.6/dist-packages (from botocore<1.15.0,>=1.14.15->boto3->pytorch_pretrained_bert) (2.6.1)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.15.0,>=1.14.15->boto3->pytorch_pretrained_bert) (1.12.0)\n",
      "Installing collected packages: pytorch-pretrained-bert\n",
      "Successfully installed pytorch-pretrained-bert-0.6.2\n",
      "Collecting transformers\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/13/33/ffb67897a6985a7b7d8e5e7878c3628678f553634bd3836404fef06ef19b/transformers-2.5.1-py3-none-any.whl (499kB)\n",
      "\u001b[K     |████████████████████████████████| 501kB 35.9MB/s \n",
      "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.28.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n",
      "Collecting sentencepiece\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/74/f4/2d5214cbf13d06e7cb2c20d84115ca25b53ea76fa1f0ade0e3c9749de214/sentencepiece-0.1.85-cp36-cp36m-manylinux1_x86_64.whl (1.0MB)\n",
      "\u001b[K     |████████████████████████████████| 1.0MB 48.2MB/s \n",
      "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.21.0)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.17.5)\n",
      "Requirement already satisfied: boto3 in /usr/local/lib/python3.6/dist-packages (from transformers) (1.11.15)\n",
      "Collecting sacremoses\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a6/b4/7a41d630547a4afd58143597d5a49e07bfd4c42914d8335b2a5657efc14b/sacremoses-0.0.38.tar.gz (860kB)\n",
      "\u001b[K     |████████████████████████████████| 870kB 52.7MB/s \n",
      "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n",
      "Collecting tokenizers==0.5.2\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d1/3f/73c881ea4723e43c1e9acf317cf407fab3a278daab3a69c98dcac511c04f/tokenizers-0.5.2-cp36-cp36m-manylinux1_x86_64.whl (3.7MB)\n",
      "\u001b[K     |████████████████████████████████| 3.7MB 52.2MB/s \n",
      "\u001b[?25hRequirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.8)\n",
      "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2019.11.28)\n",
      "Requirement already satisfied: botocore<1.15.0,>=1.14.15 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (1.14.15)\n",
      "Requirement already satisfied: s3transfer<0.4.0,>=0.3.0 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (0.3.3)\n",
      "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (0.9.4)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.12.0)\n",
      "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.0)\n",
      "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.14.1)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.6/dist-packages (from botocore<1.15.0,>=1.14.15->boto3->transformers) (2.6.1)\n",
      "Requirement already satisfied: docutils<0.16,>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore<1.15.0,>=1.14.15->boto3->transformers) (0.15.2)\n",
      "Building wheels for collected packages: sacremoses\n",
      "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for sacremoses: filename=sacremoses-0.0.38-cp36-none-any.whl size=884628 sha256=e66081947d3d76a9031120d99e9b96e8f83f1c765318d6da3f156c96ee6fb85c\n",
      "  Stored in directory: /root/.cache/pip/wheels/6d/ec/1a/21b8912e35e02741306f35f66c785f3afe94de754a0eaf1422\n",
      "Successfully built sacremoses\n",
      "Installing collected packages: sentencepiece, sacremoses, tokenizers, transformers\n",
      "Successfully installed sacremoses-0.0.38 sentencepiece-0.1.85 tokenizers-0.5.2 transformers-2.5.1\n",
      "Collecting scikit-learn==0.20.2\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/0d/3a/b92670f5c368c20329ecc4c255993fae7934564d485c3ed7ea7b8da7f741/scikit_learn-0.20.2-cp36-cp36m-manylinux1_x86_64.whl (5.4MB)\n",
      "\u001b[K     |████████████████████████████████| 5.4MB 15.5MB/s \n",
      "\u001b[?25hRequirement already satisfied: scipy>=0.13.3 in /usr/local/lib/python3.6/dist-packages (from scikit-learn==0.20.2) (1.4.1)\n",
      "Requirement already satisfied: numpy>=1.8.2 in /usr/local/lib/python3.6/dist-packages (from scikit-learn==0.20.2) (1.17.5)\n",
      "Installing collected packages: scikit-learn\n",
      "  Found existing installation: scikit-learn 0.22.1\n",
      "    Uninstalling scikit-learn-0.22.1:\n",
      "      Successfully uninstalled scikit-learn-0.22.1\n",
      "Successfully installed scikit-learn-0.20.2\n"
     ]
    }
   ],
   "source": [
    "!pip install pytorch_pretrained_bert\n",
    "!pip install transformers\n",
    "!pip install scikit-learn==0.20.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 62
    },
    "colab_type": "code",
    "id": "pevbMpL2up0X",
    "outputId": "8f1b14b2-3010-4620-82a8-d647c6cff888"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<p style=\"color: red;\">\n",
       "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
       "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
       "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
       "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import sklearn\n",
    "import torch\n",
    "import pandas as pd\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import Dataset\n",
    "from pytorch_pretrained_bert import BertModel, BertTokenizer\n",
    "root='/content/drive/My Drive/google-quest-challenge/'\n",
    "import numpy as np\n",
    "import time\n",
    "import tqdm\n",
    "\n",
    "import math\n",
    "import scipy\n",
    "import torch.nn.functional as F\n",
    "import random\n",
    "import transformers, sys, os, gc\n",
    "from transformers import (\n",
    "    BertTokenizer, BertModel, BertForSequenceClassification, BertConfig,\n",
    "    WEIGHTS_NAME, CONFIG_NAME, AdamW, get_linear_schedule_with_warmup, \n",
    "    get_cosine_schedule_with_warmup,\n",
    ")\n",
    "from torch.utils.data import DataLoader, Dataset,RandomSampler, SequentialSampler\n",
    "from transformers.modeling_bert import BertPreTrainedModel \n",
    "from sklearn.model_selection import StratifiedShuffleSplit,StratifiedKFold\n",
    "from tqdm import tqdm_notebook\n",
    "from sklearn.metrics import roc_curve \n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "sbMmn8wnutmV"
   },
   "outputs": [],
   "source": [
    "def setup_seed(seed):\n",
    "     torch.manual_seed(seed)\n",
    "     torch.cuda.manual_seed_all(seed)\n",
    "     np.random.seed(seed)\n",
    "     random.seed(seed)\n",
    "     torch.backends.cudnn.deterministic = True\n",
    "setup_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "7hDBk0A3zQdi"
   },
   "outputs": [],
   "source": [
    "\n",
    "test=[]\n",
    "weight=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "GrExBJ4AzUM2"
   },
   "outputs": [],
   "source": [
    "with open (ROOT+'data/test.txt', 'r') as f:\n",
    "  for line in f:\n",
    "    text = line\n",
    "    test.append(text.replace('\\n',''))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "XGxkJoFavhAd",
    "outputId": "d28e7d10-2869-44a6-c396-7828225e397b"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calling BertTokenizer.from_pretrained() with the path to a single file or url is deprecated\n"
     ]
    }
   ],
   "source": [
    "tokenizer=BertTokenizer.from_pretrained(BERT_TOK_ROOT)\n",
    "test_idx = []\n",
    "test_mask = []\n",
    "test_segment = []\n",
    "lenth = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "58havxDJvqHH"
   },
   "outputs": [],
   "source": [
    "for line in range(len(test)):\n",
    "  token = tokenizer.tokenize(test[line])\n",
    "  token = [\"[CLS]\"] + token + [\"[SEP]\"]\n",
    "  if len(token)> MAX_LEN:\n",
    "      raise IndexError(\"Token length more than max seq length!\")\n",
    "  lenth.append(len(token))\n",
    "  mask = [1]*len(token)+ [0]*(MAX_LEN-len(token))\n",
    "  sent = [0]*MAX_LEN\n",
    "  idx = tokenizer.convert_tokens_to_ids(token)\n",
    "  idx = idx + (MAX_LEN-len(idx))*[0]\n",
    "  test_idx.append(idx)\n",
    "  test_mask.append(mask)\n",
    "  test_segment.append(sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "iwl4CFSvDFSS"
   },
   "outputs": [],
   "source": [
    "lenths = np.array(lenth)\n",
    "lenths=lenths.reshape(-1,1)\n",
    "use = lenths\n",
    "use_shape = use.shape[1]\n",
    "use = list(use)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "2BenhHh0toQH"
   },
   "outputs": [],
   "source": [
    "class EvalDataset(Dataset):\n",
    "  def __init__(self,train_idx,train_mask,train_segment,use,label=None):\n",
    "    self.train_idx = torch.tensor(train_idx,dtype=torch.int).long()\n",
    "    self.train_mask = torch.tensor(train_mask,dtype=torch.int).long()\n",
    "    self.train_segment = torch.tensor(train_segment,dtype=torch.int).long()\n",
    "    self.use = torch.tensor(use , dtype=torch.float32)\n",
    "    self.label = None\n",
    "    if label is not None:\n",
    "      self.label = torch.tensor(label,dtype=torch.float32)\n",
    "  def __len__(self):\n",
    "    return len(self.train_idx)\n",
    "  def __getitem__(self,item):\n",
    "    if self.label is not None:\n",
    "\n",
    "      output = {\n",
    "        'train_idx' : self.train_idx[item],\n",
    "        'train_mask' : self.train_mask[item],\n",
    "        'train_segment' :self.train_segment[item],\n",
    "        'use':self.use[item],\n",
    "        'label' : self.label[item]\n",
    "    }\n",
    "    else:\n",
    "      output = {\n",
    "        'train_idx' : self.train_idx[item],\n",
    "        'train_mask' : self.train_mask[item],\n",
    "        'use' : self.use[item],\n",
    "        'train_segment' :self.train_segment[item],\n",
    "      }\n",
    "    return {key: value for key, value in output.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "jgw6IoT2eKAW"
   },
   "outputs": [],
   "source": [
    "class CLSbert(BertPreTrainedModel):\n",
    "  def __init__(self,config,use_shape):\n",
    "    super(CLSbert,self).__init__(config)\n",
    "    self.bert = BertModel(config)\n",
    "    self.dropout = nn.Dropout(0.3)\n",
    "    \n",
    "    self.softmax = nn.Softmax(dim=1)\n",
    "    self.pre = nn.Linear(2*768+use_shape,1)\n",
    "    self.linear1 = nn.Linear(2*768+use_shape,2*768+use_shape)\n",
    "    self.dropoutlist = nn.ModuleList([nn.Dropout(0.7) for _ in range(7)])\n",
    "\n",
    "    self.ln = nn.LayerNorm(2*768+use_shape)\n",
    "    self.d_model = 768\n",
    "    self.wt=torch.nn.Parameter(torch.rand((13,1),dtype=torch.float32,device=torch.device('cuda'),requires_grad=True))\n",
    "    nn.init.xavier_normal_(self.wt)\n",
    "  def forward(\n",
    "        self,\n",
    "        use,\n",
    "        input_ids=None,\n",
    "        attention_mask=None,\n",
    "        token_type_ids=None,\n",
    "        position_ids=None,\n",
    "        head_mask=None,\n",
    "        inputs_embeds=None,\n",
    "        labels=None,\n",
    "    ):\n",
    "    outputs = self.bert(\n",
    "            input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            token_type_ids=token_type_ids,\n",
    "            position_ids=position_ids,\n",
    "            head_mask=head_mask,\n",
    "            inputs_embeds=inputs_embeds,\n",
    "        )\n",
    "    w=outputs[2] \n",
    "\n",
    "    batch_size1,len_seq1,e_s1=w[1].size()\n",
    "    bert_output1 = w[-1][0][int(use[0].item())-1].unsqueeze(0) #0个batch\n",
    "    for i in range(1,batch_size1):\n",
    "        bert_output1=torch.cat((bert_output1,w[-1][i][int(use[0].item())-1].unsqueeze(0)),dim=0)\n",
    "    bert_output=w[0][:,0].reshape((-1,1,self.d_model)).to(device).clone()\n",
    "    for i in range(1,13):\n",
    "        bert_output=torch.cat((bert_output,w[i][:,0].reshape((-1,1,self.d_model)).to(device)),dim=1)\n",
    "    bert_output=bert_output.view(batch_size1,13,-1)\n",
    "    bert_output=bert_output.permute(0,2,1)\n",
    "    bert_output=torch.matmul(bert_output,self.softmax(self.dropout(self.wt)))\n",
    "    bert_output=torch.cat((bert_output.view(batch_size1,e_s1),use),dim=-1)\n",
    "    bert_output=torch.cat((bert_output,bert_output1),dim=-1)\n",
    "    l1=(self.linear1((self.dropoutlist[0]((bert_output)))))\n",
    "    l2=(self.linear1((self.dropoutlist[1]((bert_output)))))\n",
    "    l3=(self.linear1((self.dropoutlist[2]((bert_output)))))\n",
    "    l4=(self.linear1((self.dropoutlist[3]((bert_output)))))\n",
    "    l5=(self.linear1((self.dropoutlist[4]((bert_output)))))\n",
    "    l6=(self.linear1((self.dropoutlist[5]((bert_output)))))\n",
    "    l7=(self.linear1((self.dropoutlist[6]((bert_output)))))\n",
    "    l=(l1+l2+l3+l4+l5+l6+l7)/7\n",
    "\n",
    "    logits = self.pre(l)\n",
    "    return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "T6xuWKfU7glP"
   },
   "outputs": [],
   "source": [
    "\n",
    "## Stolen from transformer code base without any noble intention.\n",
    "\n",
    "## Stolen from transformer code base without any noble intention.\n",
    "class Attention(nn.Module):\n",
    "    def __init__(self, feature_dim, step_dim, bias=True, **kwargs):\n",
    "        super(Attention, self).__init__(**kwargs)\n",
    "        \n",
    "        self.supports_masking = True\n",
    "\n",
    "        self.bias = bias\n",
    "        self.feature_dim = feature_dim\n",
    "        self.step_dim = step_dim\n",
    "        self.features_dim = 0\n",
    "        \n",
    "        weight = torch.zeros(feature_dim, 1)\n",
    "        nn.init.xavier_uniform_(weight)\n",
    "        self.weight = nn.Parameter(weight)\n",
    "        \n",
    "        if bias:\n",
    "            self.b = nn.Parameter(torch.zeros(step_dim))\n",
    "        \n",
    "    def forward(self, x, mask=None):\n",
    "        feature_dim = self.feature_dim\n",
    "        step_dim = self.step_dim\n",
    "\n",
    "        eij = torch.mm(\n",
    "            x.contiguous().view(-1, feature_dim), \n",
    "            self.weight\n",
    "        ).view(-1, step_dim)\n",
    "        \n",
    "        if self.bias:\n",
    "            eij = eij + self.b\n",
    "            \n",
    "        eij = torch.tanh(eij)\n",
    "        a = torch.exp(eij)\n",
    "        \n",
    "        if mask is not None:\n",
    "            a = a * mask\n",
    "\n",
    "        a = a / torch.sum(a, 1, keepdim=True) + 1e-10\n",
    "        \n",
    "        weighted_input = x.permute(1,0,2) * torch.unsqueeze(a, -1)\n",
    "        return torch.sum(weighted_input, 1)\n",
    "class cnnbert(BertPreTrainedModel):\n",
    "\n",
    "    def __init__(self, config,kernel_sizes,num_channels,use_shape):\n",
    "        super(cnnbert, self).__init__(config)\n",
    "        self.num_labels = config.num_labels\n",
    "        self.bert = BertModel(config)\n",
    "        self.dropout = nn.Dropout(0.3)\n",
    "        self.bn = nn.LayerNorm(768)\n",
    "        self.gelu=GELU()\n",
    "        self.att1=Attention(512,21)\n",
    "        self.att2=Attention(512,20)\n",
    "        self.att3=Attention(512,19)\n",
    "        self.att4=Attention(512,18)\n",
    "        self.att5=Attention(512,13)\n",
    "        self.softmax=nn.Softmax(dim=1)\n",
    "        self.pre_cnn=nn.Linear(2*sum(num_channels)+use_shape,1)\n",
    "        self.linear = nn.Linear(2*sum(num_channels)+use_shape,2*sum(num_channels)+use_shape)\n",
    "\n",
    "        self.ln_cnn=nn.LayerNorm(sum(num_channels))\n",
    "        self.wt=torch.nn.Parameter(torch.rand((13,1),dtype=torch.float32,device=torch.device('cuda'),requires_grad=True))\n",
    "        nn.init.xavier_normal_(self.wt)\n",
    "        self.pool = GlobalAVGPool1d()\n",
    "        self.convs = nn.ModuleList()\n",
    "        for c, k in zip(num_channels, kernel_sizes):\n",
    "          self.convs.append(nn.Conv1d(in_channels = 768,\n",
    "          out_channels = c,\n",
    "          kernel_size = k))\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        use,\n",
    "        input_ids=None,\n",
    "        attention_mask=None,\n",
    "        token_type_ids=None,\n",
    "        position_ids=None,\n",
    "        head_mask=None,\n",
    "        inputs_embeds=None,\n",
    "        labels=None,\n",
    "        \n",
    "    ):\n",
    "\n",
    "        outputs = self.bert(\n",
    "           \n",
    "            input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            token_type_ids=token_type_ids,\n",
    "            position_ids=position_ids,\n",
    "            head_mask=head_mask,\n",
    "            inputs_embeds=inputs_embeds,\n",
    "        )\n",
    "\n",
    "        w1=outputs[2] \n",
    "        batch_size1,len_seq1,e_s1=w1[1].size()\n",
    "        bert_output1=w1[0].to(device)\n",
    "        bert_output1=bert_output1.unsqueeze(1)\n",
    "        for i in range(1,13):\n",
    "          bert_output1=torch.cat((bert_output1,w1[i].to(device).unsqueeze(1)),dim=1)\n",
    "        bert_output1=bert_output1.view(batch_size1,13,-1)\n",
    "        bert_output1=bert_output1.permute(0,2,1)\n",
    "        bert_output1=torch.matmul(bert_output1,((self.wt)))\n",
    "        bert_output1=bert_output1.view(batch_size1,len_seq1,e_s1)#下可接CNN或者att\n",
    "        bert_output1=self.bn(bert_output1)\n",
    "        bert_output1=bert_output1.permute(0, 2, 1)\n",
    "\n",
    "        bert_output1 = self.dropout(bert_output1)\n",
    "        conout1=self.att1(self.gelu(self.convs[0](bert_output1).permute(2,0,1)))\n",
    "        conout2=self.att2(self.gelu(self.convs[1](bert_output1).permute(2,0,1)))\n",
    "        conout3=self.att3(self.gelu(self.convs[2](bert_output1).permute(2,0,1)))\n",
    "        conout4=self.att4(self.gelu(self.convs[3](bert_output1).permute(2,0,1)))\n",
    "        conout5=self.att5(self.gelu(self.convs[4](bert_output1).permute(2,0,1)))\n",
    "        conout=torch.cat((conout1,conout2,conout3,conout4,conout5),dim=1)\n",
    "        encoding =torch.cat([self.pool(self.gelu(conv(bert_output1))).squeeze(-1) for conv in self.convs], dim=1)\n",
    "       \n",
    "        #lin_output = F.relu(self.bn(encoding)) ## Note : This Linear layer is added without expert supervision . This will worsen the results . \n",
    "        encoding=torch.cat((encoding,conout,use),dim=1)\n",
    "        #encoding =torch.cat([self.pool(self.gelu(conv(bert_output1))).squeeze(-1) for conv in self.convs], dim=1)\n",
    "        #lin_output = F.relu(self.bn(encoding)) ## Note : This Linear layer is added without expert supervision . This will worsen the results . \n",
    "        #lin_output = F.relu(self.bn(encoding)) ## Note : This Linear layer is added without expert supervision . This will worsen the results .                                     ## But you are smarter than me , so you will figure out,how to customize better.\n",
    "        logits = self.pre_cnn((encoding))\n",
    "        return logits\n",
    "class GlobalAVGPool1d(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(GlobalAVGPool1d, self).__init__()\n",
    "    def forward(self, x):\n",
    "         # x shape: (batch_size, channel, seq_len)\n",
    "        return F.avg_pool1d(x, kernel_size=x.shape[2]) # shape: (batch_size, channel, 1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "Uovr8u0THkUm"
   },
   "outputs": [],
   "source": [
    "class GELU(nn.Module):\n",
    "    \"\"\"\n",
    "    Paper Section 3.4, last paragraph notice that BERT used the GELU instead of RELU\n",
    "    \"\"\"\n",
    "\n",
    "    def forward(self, x):\n",
    "        return 0.5 * x * (1 + torch.tanh(math.sqrt(2 / math.pi) * (x + 0.044715 * torch.pow(x, 3))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "sT-VoFxGAt8h"
   },
   "outputs": [],
   "source": [
    "class EMA():\n",
    "    def __init__(self, model, decay):\n",
    "        self.model = model\n",
    "        self.decay = decay\n",
    "        self.shadow = {}\n",
    "        self.backup = {}\n",
    "\n",
    "    def register(self):\n",
    "        for name, param in self.model.named_parameters():\n",
    "            if param.requires_grad:\n",
    "                self.shadow[name] = param.data.clone()\n",
    "\n",
    "    def update(self):\n",
    "        for name, param in self.model.named_parameters():\n",
    "            if param.requires_grad:\n",
    "                assert name in self.shadow\n",
    "                new_average = (1.0 - self.decay) * param.data + self.decay * self.shadow[name]\n",
    "                self.shadow[name] = new_average.clone()\n",
    "\n",
    "    def apply_shadow(self):\n",
    "        for name, param in self.model.named_parameters():\n",
    "            if param.requires_grad:\n",
    "                assert name in self.shadow\n",
    "                self.backup[name] = param.data\n",
    "                param.data = self.shadow[name]\n",
    "\n",
    "    def restore(self):\n",
    "        for name, param in self.model.named_parameters():\n",
    "            if param.requires_grad:\n",
    "                assert name in self.backup\n",
    "                param.data = self.backup[name]\n",
    "        self.backup = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "E-9D8IRqAw4K"
   },
   "outputs": [],
   "source": [
    "def predict_model(model,predict_loader ,pre_shape,batch_size , ema, config=None):\n",
    "  #ema.apply_shadow()\n",
    "  model.eval()\n",
    "  acc_lm = 0\n",
    "  acc_sent = 0\n",
    "  avg_loss = 0\n",
    "  pred = np.zeros((pre_shape))\n",
    "  with torch.no_grad():\n",
    "    for idx, batch in tqdm_notebook(enumerate(predict_loader),mininterval=2,desc='--Valing',leave=False):\n",
    "      input_ids = batch['train_idx'].to(device)\n",
    "      input_mask = batch['train_mask'].to(device)\n",
    "      input_segments = batch['train_segment'].to(device)\n",
    "      use = batch['use'].to(device)\n",
    "      output_train = model(use=use,input_ids = input_ids.long(),\n",
    "                              labels = None,\n",
    "                              attention_mask = input_mask,\n",
    "                              token_type_ids = input_segments,)\n",
    "      pred[idx*batch_size : (idx+1)*batch_size]=(torch.sigmoid(output_train.cpu().view(-1)))\n",
    "  #ema.restore()\n",
    "  return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "6BpfSR1TwM2X"
   },
   "outputs": [],
   "source": [
    "bert_model_config = BERT_ROOT+'/bert_config.json'\n",
    "bert_config = BertConfig.from_json_file(bert_model_config)\n",
    "bert_config.num_labels = 1\n",
    "bert_config.output_hidden_states=True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "vFgFxWbXc8a6"
   },
   "outputs": [],
   "source": [
    "dataset = EvalDataset(test_idx,test_mask,test_segment,use)\n",
    "pre_shape = len(test_idx)\n",
    "pre_loader = DataLoader(dataset,batch_size=128,shuffle=False)\n",
    "pred = np.zeros((pre_shape))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "_GVIL53vCNsh"
   },
   "outputs": [],
   "source": [
    "device = torch.device('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "SYom4u0RCctU",
    "outputId": "83d42361-efd4-466f-b33d-27dffa15e412"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4189"
      ]
     },
     "execution_count": 21,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 17,
     "referenced_widgets": [
      "1f66790bb3c54248bfd5003873070ae2",
      "68c4ba6993cc4b398af5cb542a8cbf4b",
      "3724c182fe8b4488a1bda3b6a8e95df0",
      "9cabd831001a4ac48b5d6bebce103aec",
      "bb5c69b9581145149d266e3ffe50f2d5",
      "28bc3e8cc9804a6e8379aa17cd4ed1c9",
      "20db325bf0f44e388868885ddf3cddf6",
      "a771833e611947b7aaf43c51cf6eff43",
      "ff7b8fd061504d278e00207278cbac9a",
      "4ac7fd89920547cdaf8114f23cc871d2",
      "dbb6a8ece626491a968f863b42b4c4c1",
      "be5c2cb3a65b4096a79af0ccab2dfc01",
      "62ee2992e00f486d8b85fe579e476935",
      "a2fc6a875ef84b738d89f9c8c6d35fec",
      "0bb29c99ad12467aa54e398552836d50",
      "339bd1771b79442fbf9f4d29f19835da",
      "299b4ec883fe411e8f3855ae7b617889",
      "1557b49119ad4178b1eefb1b10310399",
      "5524f05a2fd7458b94e582022080f21f",
      "e639389ae7974298a93aba6c22913c63",
      "0dc563149ee54b689f91bfd729d699b6",
      "12e5b37b5d414e4c863ff100614b41ac",
      "a553a460195149abb49a61decc0b8df5",
      "4271ee37baf84b07903c4e55df9b392b",
      "1ae83eb9565d4ca7b6daa296e87c191d",
      "cd66b5b258ca45b7a502acb775fb22c8",
      "fcd2d2a7fe9c45c1820e359f760c6871",
      "a191626f58fb44a987949735e5f2efd8",
      "8076ac5456f6417286ddc98f3a6dec7a",
      "83455a95e31f473cba1b27cfe1691559",
      "b3856ec0db874822865b818647be0502",
      "d6feadcc3899496f8a9c68a79e093232"
     ]
    },
    "colab_type": "code",
    "id": "k2sgYpjwe2Ku",
    "outputId": "e9034593-72ff-4ca2-ea09-8027feff0208"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1f66790bb3c54248bfd5003873070ae2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', description='--Valing', max=1, style=ProgressStyle(descr…"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ff7b8fd061504d278e00207278cbac9a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', description='--Valing', max=1, style=ProgressStyle(descr…"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "299b4ec883fe411e8f3855ae7b617889",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', description='--Valing', max=1, style=ProgressStyle(descr…"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1ae83eb9565d4ca7b6daa296e87c191d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', description='--Valing', max=1, style=ProgressStyle(descr…"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "for i in [1,2,3,5]:\n",
    "  kernel_sizes,nums_channels = [2,3,4,5,10], [512,512,512,512,512]\n",
    "  model = cnnbert.from_pretrained(BERT_ROOT,kernel_sizes=kernel_sizes,num_channels=nums_channels,use_shape=use_shape,config = bert_config)\n",
    "  model.to(device)\n",
    "  #model.load_state_dict(torch.load('/content/drive/My Drive/dl/推荐评论/CNN/best_param_score_{}.pkl'.format(i)))\n",
    "  ema=torch.load('/content/drive/My Drive/dl/推荐评论/0.96840版本基础 伪标签/CNN/EMA{}.pkl'.format(i))\n",
    "  ema.model = model\n",
    "  ema.apply_shadow()\n",
    "  pred += predict_model(model,pre_loader ,pre_shape,128, ema,config=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "7kNC1EYTm22G"
   },
   "outputs": [],
   "source": [
    "for i in [1,2,3,5]:\n",
    "  model = CLSbert.from_pretrained(BERT_ROOT,use_shape = use_shape,config = bert_config)\n",
    "  model.to(device)\n",
    "  #model.load_state_dict(torch.load('/content/drive/My Drive/dl/推荐评论/CLS/best_param_score_{}'.format(i)))\n",
    "  ema=torch.load('/content/drive/My Drive/dl/推荐评论/0.96840版本基础 伪标签/'+'CLS/EMA_{}'.format(i))\n",
    "  ema.model = model\n",
    "  ema.apply_shadow()\n",
    "  pred += predict_model(model,pre_loader ,pre_shape,128, ema,config=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "DnOmXvpfEBgj"
   },
   "outputs": [],
   "source": [
    "sub = pd.read_csv('/content/drive/My Drive/dl/推荐评论/sub.csv') \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "9eQrOJWlJ94d"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "TjtUaEahEhLD"
   },
   "outputs": [],
   "source": [
    "sub.loc[:,'Prediction']=(pred)/8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 195
    },
    "colab_type": "code",
    "id": "SsNhdGJ_p6Ol",
    "outputId": "d310f3ff-a0d9-47cb-bf26-68a71b0ca4be"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.963567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.955745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.977581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.000950</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID  Prediction\n",
       "0   0    0.000372\n",
       "1   1    0.963567\n",
       "2   2    0.955745\n",
       "3   3    0.977581\n",
       "4   4    0.000950"
      ]
     },
     "execution_count": 29,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "05C7LYj6l0TG"
   },
   "outputs": [],
   "source": [
    "sub.to_csv('submission_random.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "3R1JHbSCpvdw"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "predict.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "0bb29c99ad12467aa54e398552836d50": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "0dc563149ee54b689f91bfd729d699b6": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "12e5b37b5d414e4c863ff100614b41ac": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "1557b49119ad4178b1eefb1b10310399": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "1ae83eb9565d4ca7b6daa296e87c191d": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_fcd2d2a7fe9c45c1820e359f760c6871",
       "IPY_MODEL_a191626f58fb44a987949735e5f2efd8"
      ],
      "layout": "IPY_MODEL_cd66b5b258ca45b7a502acb775fb22c8"
     }
    },
    "1f66790bb3c54248bfd5003873070ae2": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_3724c182fe8b4488a1bda3b6a8e95df0",
       "IPY_MODEL_9cabd831001a4ac48b5d6bebce103aec"
      ],
      "layout": "IPY_MODEL_68c4ba6993cc4b398af5cb542a8cbf4b"
     }
    },
    "20db325bf0f44e388868885ddf3cddf6": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "28bc3e8cc9804a6e8379aa17cd4ed1c9": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "299b4ec883fe411e8f3855ae7b617889": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_5524f05a2fd7458b94e582022080f21f",
       "IPY_MODEL_e639389ae7974298a93aba6c22913c63"
      ],
      "layout": "IPY_MODEL_1557b49119ad4178b1eefb1b10310399"
     }
    },
    "339bd1771b79442fbf9f4d29f19835da": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "3724c182fe8b4488a1bda3b6a8e95df0": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "IntProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "IntProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "info",
      "description": "--Valing",
      "description_tooltip": null,
      "layout": "IPY_MODEL_28bc3e8cc9804a6e8379aa17cd4ed1c9",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_bb5c69b9581145149d266e3ffe50f2d5",
      "value": 1
     }
    },
    "4271ee37baf84b07903c4e55df9b392b": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "4ac7fd89920547cdaf8114f23cc871d2": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5524f05a2fd7458b94e582022080f21f": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "IntProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "IntProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "info",
      "description": "--Valing",
      "description_tooltip": null,
      "layout": "IPY_MODEL_12e5b37b5d414e4c863ff100614b41ac",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_0dc563149ee54b689f91bfd729d699b6",
      "value": 1
     }
    },
    "62ee2992e00f486d8b85fe579e476935": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "68c4ba6993cc4b398af5cb542a8cbf4b": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "8076ac5456f6417286ddc98f3a6dec7a": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "83455a95e31f473cba1b27cfe1691559": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9cabd831001a4ac48b5d6bebce103aec": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_a771833e611947b7aaf43c51cf6eff43",
      "placeholder": "​",
      "style": "IPY_MODEL_20db325bf0f44e388868885ddf3cddf6",
      "value": "32it [00:06,  5.04it/s]"
     }
    },
    "a191626f58fb44a987949735e5f2efd8": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_d6feadcc3899496f8a9c68a79e093232",
      "placeholder": "​",
      "style": "IPY_MODEL_b3856ec0db874822865b818647be0502",
      "value": "32it [00:06,  5.00it/s]"
     }
    },
    "a2fc6a875ef84b738d89f9c8c6d35fec": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a553a460195149abb49a61decc0b8df5": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "a771833e611947b7aaf43c51cf6eff43": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b3856ec0db874822865b818647be0502": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "bb5c69b9581145149d266e3ffe50f2d5": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "be5c2cb3a65b4096a79af0ccab2dfc01": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_339bd1771b79442fbf9f4d29f19835da",
      "placeholder": "​",
      "style": "IPY_MODEL_0bb29c99ad12467aa54e398552836d50",
      "value": "33it [00:06,  5.21it/s]"
     }
    },
    "cd66b5b258ca45b7a502acb775fb22c8": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d6feadcc3899496f8a9c68a79e093232": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "dbb6a8ece626491a968f863b42b4c4c1": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "IntProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "IntProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "info",
      "description": "--Valing",
      "description_tooltip": null,
      "layout": "IPY_MODEL_a2fc6a875ef84b738d89f9c8c6d35fec",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_62ee2992e00f486d8b85fe579e476935",
      "value": 1
     }
    },
    "e639389ae7974298a93aba6c22913c63": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_4271ee37baf84b07903c4e55df9b392b",
      "placeholder": "​",
      "style": "IPY_MODEL_a553a460195149abb49a61decc0b8df5",
      "value": "32it [00:06,  5.07it/s]"
     }
    },
    "fcd2d2a7fe9c45c1820e359f760c6871": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "IntProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "IntProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "info",
      "description": "--Valing",
      "description_tooltip": null,
      "layout": "IPY_MODEL_83455a95e31f473cba1b27cfe1691559",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_8076ac5456f6417286ddc98f3a6dec7a",
      "value": 1
     }
    },
    "ff7b8fd061504d278e00207278cbac9a": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_dbb6a8ece626491a968f863b42b4c4c1",
       "IPY_MODEL_be5c2cb3a65b4096a79af0ccab2dfc01"
      ],
      "layout": "IPY_MODEL_4ac7fd89920547cdaf8114f23cc871d2"
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
