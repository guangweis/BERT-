{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "A2jdkmcrGD8t"
   },
   "outputs": [],
   "source": [
    "ROOT='/content/drive/My Drive/dl/美团/CLS/'\n",
    "BERT_ROOT='/content/drive/My Drive/dl/google-quest-challenge/pretrained-bert-models-for-pytorch/新建文件夹/bert-base-chinese/'\n",
    "BERT_TOK_ROOT='/content/drive/My Drive/dl/google-quest-challenge/pretrained-bert-models-for-pytorch/bert-base-chinese-vocab.txt'\n",
    "MAX_LEN=22"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "2pcNm4IbrzjB",
    "outputId": "15eb3874-2aa6-46a1-9d79-6342d0e4cf22"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pytorch_pretrained_bert\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d7/e0/c08d5553b89973d9a240605b9c12404bcf8227590de62bae27acbcfe076b/pytorch_pretrained_bert-0.6.2-py3-none-any.whl (123kB)\n",
      "\r",
      "\u001b[K     |██▋                             | 10kB 15.2MB/s eta 0:00:01\r",
      "\u001b[K     |█████▎                          | 20kB 3.0MB/s eta 0:00:01\r",
      "\u001b[K     |████████                        | 30kB 3.4MB/s eta 0:00:01\r",
      "\u001b[K     |██████████▋                     | 40kB 3.1MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████▎                  | 51kB 3.4MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████▉                | 61kB 4.1MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████▌             | 71kB 4.1MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████▏          | 81kB 4.0MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████▉        | 92kB 4.5MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████████▌     | 102kB 4.5MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████████████▏  | 112kB 4.5MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████████████▊| 122kB 4.5MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████████████| 133kB 4.5MB/s \n",
      "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from pytorch_pretrained_bert) (2.21.0)\n",
      "Requirement already satisfied: boto3 in /usr/local/lib/python3.6/dist-packages (from pytorch_pretrained_bert) (1.11.15)\n",
      "Requirement already satisfied: torch>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from pytorch_pretrained_bert) (1.4.0)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from pytorch_pretrained_bert) (4.28.1)\n",
      "Requirement already satisfied: regex in /usr/local/lib/python3.6/dist-packages (from pytorch_pretrained_bert) (2019.12.20)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from pytorch_pretrained_bert) (1.17.5)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch_pretrained_bert) (2.8)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch_pretrained_bert) (3.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch_pretrained_bert) (2019.11.28)\n",
      "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch_pretrained_bert) (1.24.3)\n",
      "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->pytorch_pretrained_bert) (0.9.4)\n",
      "Requirement already satisfied: botocore<1.15.0,>=1.14.15 in /usr/local/lib/python3.6/dist-packages (from boto3->pytorch_pretrained_bert) (1.14.15)\n",
      "Requirement already satisfied: s3transfer<0.4.0,>=0.3.0 in /usr/local/lib/python3.6/dist-packages (from boto3->pytorch_pretrained_bert) (0.3.3)\n",
      "Requirement already satisfied: docutils<0.16,>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore<1.15.0,>=1.14.15->boto3->pytorch_pretrained_bert) (0.15.2)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.6/dist-packages (from botocore<1.15.0,>=1.14.15->boto3->pytorch_pretrained_bert) (2.6.1)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.15.0,>=1.14.15->boto3->pytorch_pretrained_bert) (1.12.0)\n",
      "Installing collected packages: pytorch-pretrained-bert\n",
      "Successfully installed pytorch-pretrained-bert-0.6.2\n",
      "Collecting transformers\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/13/33/ffb67897a6985a7b7d8e5e7878c3628678f553634bd3836404fef06ef19b/transformers-2.5.1-py3-none-any.whl (499kB)\n",
      "\u001b[K     |████████████████████████████████| 501kB 5.1MB/s \n",
      "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n",
      "Requirement already satisfied: boto3 in /usr/local/lib/python3.6/dist-packages (from transformers) (1.11.15)\n",
      "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.28.1)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n",
      "Collecting sentencepiece\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/74/f4/2d5214cbf13d06e7cb2c20d84115ca25b53ea76fa1f0ade0e3c9749de214/sentencepiece-0.1.85-cp36-cp36m-manylinux1_x86_64.whl (1.0MB)\n",
      "\u001b[K     |████████████████████████████████| 1.0MB 55.0MB/s \n",
      "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.21.0)\n",
      "Collecting tokenizers==0.5.2\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d1/3f/73c881ea4723e43c1e9acf317cf407fab3a278daab3a69c98dcac511c04f/tokenizers-0.5.2-cp36-cp36m-manylinux1_x86_64.whl (3.7MB)\n",
      "\u001b[K     |████████████████████████████████| 3.7MB 44.0MB/s \n",
      "\u001b[?25hCollecting sacremoses\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a6/b4/7a41d630547a4afd58143597d5a49e07bfd4c42914d8335b2a5657efc14b/sacremoses-0.0.38.tar.gz (860kB)\n",
      "\u001b[K     |████████████████████████████████| 870kB 37.9MB/s \n",
      "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.17.5)\n",
      "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (0.9.4)\n",
      "Requirement already satisfied: s3transfer<0.4.0,>=0.3.0 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (0.3.3)\n",
      "Requirement already satisfied: botocore<1.15.0,>=1.14.15 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (1.14.15)\n",
      "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2019.11.28)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.8)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.12.0)\n",
      "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.0)\n",
      "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.14.1)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.6/dist-packages (from botocore<1.15.0,>=1.14.15->boto3->transformers) (2.6.1)\n",
      "Requirement already satisfied: docutils<0.16,>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore<1.15.0,>=1.14.15->boto3->transformers) (0.15.2)\n",
      "Building wheels for collected packages: sacremoses\n",
      "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for sacremoses: filename=sacremoses-0.0.38-cp36-none-any.whl size=884628 sha256=24f08f4186ab7f0a3a6bbceebc886b12358ce3839a77fe1f4f111c89f234268c\n",
      "  Stored in directory: /root/.cache/pip/wheels/6d/ec/1a/21b8912e35e02741306f35f66c785f3afe94de754a0eaf1422\n",
      "Successfully built sacremoses\n",
      "Installing collected packages: sentencepiece, tokenizers, sacremoses, transformers\n",
      "Successfully installed sacremoses-0.0.38 sentencepiece-0.1.85 tokenizers-0.5.2 transformers-2.5.1\n",
      "Collecting scikit-learn==0.21.3\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a0/c5/d2238762d780dde84a20b8c761f563fe882b88c5a5fb03c056547c442a19/scikit_learn-0.21.3-cp36-cp36m-manylinux1_x86_64.whl (6.7MB)\n",
      "\u001b[K     |████████████████████████████████| 6.7MB 5.1MB/s \n",
      "\u001b[?25hRequirement already satisfied: scipy>=0.17.0 in /usr/local/lib/python3.6/dist-packages (from scikit-learn==0.21.3) (1.4.1)\n",
      "Requirement already satisfied: numpy>=1.11.0 in /usr/local/lib/python3.6/dist-packages (from scikit-learn==0.21.3) (1.17.5)\n",
      "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn==0.21.3) (0.14.1)\n",
      "Installing collected packages: scikit-learn\n",
      "  Found existing installation: scikit-learn 0.22.1\n",
      "    Uninstalling scikit-learn-0.22.1:\n",
      "      Successfully uninstalled scikit-learn-0.22.1\n",
      "Successfully installed scikit-learn-0.21.3\n"
     ]
    }
   ],
   "source": [
    "!pip install pytorch_pretrained_bert\n",
    "!pip install transformers\n",
    "!pip install scikit-learn==0.21.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "8MA4uRWWz5Rw"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = \"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "OhJTj15qk7Ts"
   },
   "outputs": [],
   "source": [
    "import sklearn\n",
    "import torch\n",
    "import pandas as pd\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import Dataset\n",
    "from pytorch_pretrained_bert import BertModel, BertTokenizer\n",
    "root='/content/drive/My Drive/google-quest-challenge/'\n",
    "import numpy as np\n",
    "import time\n",
    "import tqdm\n",
    "import math\n",
    "import scipy\n",
    "from tqdm import tqdm_notebook\n",
    "import torch.nn.functional as F\n",
    "import random\n",
    "import transformers, sys, os, gc\n",
    "from transformers import (\n",
    "    BertTokenizer, BertModel, BertForSequenceClassification, BertConfig,\n",
    "    WEIGHTS_NAME, CONFIG_NAME, AdamW, get_linear_schedule_with_warmup, \n",
    "    get_cosine_schedule_with_warmup,\n",
    ")\n",
    "from torch.utils.data import DataLoader, Dataset,RandomSampler, SequentialSampler\n",
    "from transformers.modeling_bert import BertPreTrainedModel \n",
    "from sklearn.model_selection import StratifiedShuffleSplit,StratifiedKFold\n",
    "from tqdm import tqdm_notebook\n",
    "from sklearn.metrics import roc_curve \n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HNY8eyW-tazi"
   },
   "source": [
    "美团10w\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 570
    },
    "colab_type": "code",
    "id": "piaAdgWArvfn",
    "outputId": "41a988bb-db16-49ba-cbd6-715965eb276d"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>shopid</th>\n",
       "      <th>data</th>\n",
       "      <th>content</th>\n",
       "      <th>id</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>144693498362135320,\"</td>\n",
       "      <td>2018-10-26</td>\n",
       "      <td>#往后余生#很惊艳，女朋友很喜欢，很满意的一次购物，服务态度也好，满足了我的要求</td>\n",
       "      <td>E***4</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>144693498362135320,\"</td>\n",
       "      <td>2018-07-11</td>\n",
       "      <td>#一生所爱#真漂亮，同事们都说好看，谢谢老公送的蛋糕，天鹅是可以吃的巧克力做的，很赞，总之很开心。</td>\n",
       "      <td>C***静</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>144693498362135320,\"</td>\n",
       "      <td>2018-09-29</td>\n",
       "      <td>……味道不错……</td>\n",
       "      <td>琪***…</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>144693498362135320,\"</td>\n",
       "      <td>2018-01-28</td>\n",
       "      <td>棒棒的   水果多而且奶油不腻   很好的蛋糕  鼓励下#好好吃的浆果蛋糕#</td>\n",
       "      <td>匿***户</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>144693498362135320,\"</td>\n",
       "      <td>2017-12-06</td>\n",
       "      <td>包装赞 口味佳 很适合女孩子 发光生日帽特别有气氛</td>\n",
       "      <td>匿***户</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79311</th>\n",
       "      <td>144955603036378139,\"</td>\n",
       "      <td>2017-01-18</td>\n",
       "      <td>这是我买过的最轻的蛋糕了，外观还可以就是不知道吃起来怎么样，但愿好吃吧</td>\n",
       "      <td>f***6</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79312</th>\n",
       "      <td>144955603036378139,\"</td>\n",
       "      <td>2017-03-05</td>\n",
       "      <td>真是大大的惊喜，物超所值，不锈钢的精致餐具，水果丰富，品质太高了；一下成粉丝啊，哈哈，大赞！</td>\n",
       "      <td>B***2</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79313</th>\n",
       "      <td>144955603036378139,\"</td>\n",
       "      <td>2017-02-13</td>\n",
       "      <td>真是在买蛋糕啊，连个小盘子 叉子蜡烛什么都没有，对的起这个价格吗  坑爹</td>\n",
       "      <td>s***5</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79314</th>\n",
       "      <td>144955603036378139,\"</td>\n",
       "      <td>2018-05-27</td>\n",
       "      <td>之前在这家定过生日蛋糕觉得挺好，本着信任原则定了冰淇淋蛋糕，但这个冰淇淋蛋糕实在是恕不敢恭维...</td>\n",
       "      <td>你***哥</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79315</th>\n",
       "      <td>144955603036378139,\"</td>\n",
       "      <td>2018-09-15</td>\n",
       "      <td>最差的一次购物，已经投诉</td>\n",
       "      <td>匿***户</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>79316 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     shopid       data  ...     id score\n",
       "0      144693498362135320,\" 2018-10-26  ...  E***4   5.0\n",
       "1      144693498362135320,\" 2018-07-11  ...  C***静   5.0\n",
       "2      144693498362135320,\" 2018-09-29  ...  琪***…   5.0\n",
       "3      144693498362135320,\" 2018-01-28  ...  匿***户   5.0\n",
       "4      144693498362135320,\" 2017-12-06  ...  匿***户   5.0\n",
       "...                     ...        ...  ...    ...   ...\n",
       "79311  144955603036378139,\" 2017-01-18  ...  f***6   4.0\n",
       "79312  144955603036378139,\" 2017-03-05  ...  B***2   5.0\n",
       "79313  144955603036378139,\" 2017-02-13  ...  s***5   3.0\n",
       "79314  144955603036378139,\" 2018-05-27  ...  你***哥   1.0\n",
       "79315  144955603036378139,\" 2018-09-15  ...  匿***户   1.0\n",
       "\n",
       "[79316 rows x 5 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_excel('/content/drive/My Drive/dl/美团/data/评论.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "rHrTTG8Ox7gt",
    "outputId": "2dfbf9d7-23ad-4891-e5e0-f75c1b03fd35"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2179"
      ]
     },
     "execution_count": 8,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['score'].isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "o_92pza2vrFZ"
   },
   "source": [
    "# **补全**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "WZUVCI-zseo2"
   },
   "outputs": [],
   "source": [
    "df['score']=df['score'].fillna(3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "QOUpRRxfEWHd"
   },
   "outputs": [],
   "source": [
    "labels = df['score'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "E9UF9a0K_Ojw"
   },
   "outputs": [],
   "source": [
    "import re\n",
    "def clean_numbers(text):\n",
    "  if type(text)!= int:\n",
    "    text = text.strip().replace(' ','').replace('\\t','')\n",
    "    text=re.sub(r'\\W+',' ',text)\n",
    "  return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "WS15IcyoQmf1"
   },
   "outputs": [],
   "source": [
    "labels_sent = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "NCcUUIWVvR88"
   },
   "outputs": [],
   "source": [
    "df['content']=df['content'].apply(lambda x: clean_numbers(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "BJwLNwrMyNwD"
   },
   "outputs": [],
   "source": [
    "train_data=df['content'].values\n",
    "train_label_sent = torch.tensor(df['score'].values-1,dtype=torch.int).long()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "AMEL-y3q9-yA"
   },
   "outputs": [],
   "source": [
    "train_meituan=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "kiVQyZ9gqBmK"
   },
   "outputs": [],
   "source": [
    "for line in range(len(train_data)):\n",
    "  if type(train_data[line]) != int:\n",
    "    train_data[line] = train_data[line].replace(' ','')\n",
    "    if len(train_data[line])<=20:\n",
    "      train_meituan.append(train_data[line])\n",
    "      labels_sent.append(labels[line])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "mIjv2OqcqvG1"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "0eVe9biAC1yJ",
    "outputId": "175ff0d3-fa70-4a3c-fd76-0543b7abcfe1"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calling BertTokenizer.from_pretrained() with the path to a single file or url is deprecated\n"
     ]
    }
   ],
   "source": [
    "tokenizer=BertTokenizer.from_pretrained(BERT_TOK_ROOT)\n",
    "train_meituan_idx = []\n",
    "train_meituan_mask = []\n",
    "train_meituan_segment = []\n",
    "train_labels_meituan = []\n",
    "train_meituan_tfidf = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "fEgIIPFur4js"
   },
   "outputs": [],
   "source": [
    "lenth_meituan=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "HBEp6-77C9Mq"
   },
   "outputs": [],
   "source": [
    "for line in range(len(train_meituan)):\n",
    "  token = tokenizer.tokenize(train_meituan[line])\n",
    "  token = [\"[CLS]\"] + token + [\"[SEP]\"]\n",
    "  if len(token)>MAX_LEN:\n",
    "    continue\n",
    "  train_meituan_tfidf.append(train_meituan[line])\n",
    "  train_labels_meituan.append(labels_sent)\n",
    "  lenth_meituan.append(len(token))\n",
    "  if len(token)> MAX_LEN:\n",
    "      print(len(token))\n",
    "      raise IndexError(\"Token length more than max seq length!\")\n",
    "\n",
    "  mask = [1]*len(token)+ [0]*(MAX_LEN-len(token))\n",
    "  sent = [0]*MAX_LEN\n",
    "  idx = tokenizer.convert_tokens_to_ids(token)\n",
    "  idx = idx + (MAX_LEN-len(idx))*[0]\n",
    "  train_meituan_idx.append(idx)\n",
    "  train_meituan_mask.append(mask)\n",
    "  train_meituan_segment.append(sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "xSqcWYD3UFkT"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MIFVJmy_vAz7"
   },
   "source": [
    "# **饿了么**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "xbzZyJsyttPw"
   },
   "outputs": [],
   "source": [
    "train_elm_txt=[]\n",
    "labels_elm=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "XQtKWhVQr2lz"
   },
   "outputs": [],
   "source": [
    "with open('/content/drive/My Drive/dl/美团/data/waimai_10k.csv.txt','r') as f:\n",
    "  for line in f:\n",
    "    data=line.strip().replace(' ','').replace('\\n','').replace(',','')\n",
    "    data=re.sub(r'\\W+',' ',data)\n",
    "    labels_elm.append(data[0])\n",
    "    train_elm_txt.append(data[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "Fma2ICkQtUMF"
   },
   "outputs": [],
   "source": [
    "train_elm_idx = []\n",
    "train_elm_mask = []\n",
    "train_elm_segment = []\n",
    "lenth_elm = []\n",
    "train_elm_tiidf = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "4dLZvKoNuzgK"
   },
   "outputs": [],
   "source": [
    "for line in range(len(train_elm_txt)):\n",
    "  token = tokenizer.tokenize(train_elm_txt[line])\n",
    "  token = [\"[CLS]\"] + token + [\"[SEP]\"]\n",
    "  if len(token)>MAX_LEN:\n",
    "    continue\n",
    "  train_elm_tiidf.append(train_elm_txt[line])\n",
    "  lenth_elm.append(len(token))\n",
    "  if len(token)> MAX_LEN:\n",
    "      print(len(token))\n",
    "      raise IndexError(\"Token length more than max seq length!\")\n",
    "\n",
    "  mask = [1]*len(token)+ [0]*(MAX_LEN-len(token))\n",
    "  sent = [0]*MAX_LEN\n",
    "  idx = tokenizer.convert_tokens_to_ids(token)\n",
    "  idx = idx + (MAX_LEN-len(idx))*[0]\n",
    "  train_elm_idx.append(idx)\n",
    "  train_elm_mask.append(mask)\n",
    "  train_elm_segment.append(sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "2O-0W44Y57jB",
    "outputId": "faa94a54-81fb-418a-8e61-611e5385286a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(48552, 7814)"
      ]
     },
     "execution_count": 25,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_meituan_tfidf),len(train_elm_tiidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "zsJMdacK51qu"
   },
   "outputs": [],
   "source": [
    "train_tfidf = train_meituan_tfidf+train_elm_tiidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "36EwBATF6BtH",
    "outputId": "9c58169c-127d-46bb-dd09-9be89a071b16"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "56366"
      ]
     },
     "execution_count": 27,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "UYWjNA0Gyb5S"
   },
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import TruncatedSVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "RgoHkWRkyPax"
   },
   "outputs": [],
   "source": [
    "# text_encoder = Pipeline([\n",
    "#     ('Text-TF-IDF', TfidfVectorizer(ngram_range=(1, 3))),\n",
    "#     ('Text-SVD', TruncatedSVD(n_components = 600))], verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "AqhWDvPW7ZIY"
   },
   "outputs": [],
   "source": [
    "# text_encoder=torch.load('/content/drive/My Drive/dl/推荐评论/text_encoder.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 50
    },
    "colab_type": "code",
    "id": "cLxbO6qH1kEV",
    "outputId": "465656d2-a325-4f9f-e5db-4372bccdbfbe"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ....... (step 1 of 2) Processing Text-TF-IDF, total=   0.4s\n",
      "[Pipeline] .......... (step 2 of 2) Processing Text-SVD, total= 1.5min\n"
     ]
    }
   ],
   "source": [
    "# tfidf=text_encoder.fit_transform(train_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "3Vr5l9FE7Vwa"
   },
   "outputs": [],
   "source": [
    "# torch.save(train_tfidf,'/content/drive/My Drive/dl/推荐评论/CNN/w20_train_tfidf.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "r97WqYhH2oKu"
   },
   "outputs": [],
   "source": [
    "lenths = np.array(lenth_meituan+lenth_elm)\n",
    "lenths=lenths.reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "0b9g5nBq2LjT",
    "outputId": "80cb361f-6116-418d-c40a-a17ef6bc1ad6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(56366, 901)\n"
     ]
    }
   ],
   "source": [
    "# use = np.hstack( (lenths,tfidf))\n",
    "# print(use.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 134
    },
    "colab_type": "code",
    "id": "4rPCxxB27O6B",
    "outputId": "81313852-e88a-4b28-e17f-b4c45966cf88"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 40,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "5neXzDZO6inv"
   },
   "outputs": [],
   "source": [
    "# torch.save(use,train_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "bhXH01SsYLg9"
   },
   "outputs": [],
   "source": [
    "train_w20_idx=train_meituan_idx+train_elm_idx\n",
    "train_w20_mask = train_meituan_mask+train_elm_mask\n",
    "train_w20_segment = train_meituan_segment+train_elm_mask\n",
    "train_w20_lenths = lenth_meituan+lenth_elm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "9vqH4cBkYuNn"
   },
   "outputs": [],
   "source": [
    "train_w20_lenths = np.array(train_w20_lenths)\n",
    "train_w20_lenths=train_w20_lenths.reshape(-1,1)\n",
    "use = train_w20_lenths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "lbKheC4taCgZ"
   },
   "outputs": [],
   "source": [
    "use_shape = use.shape[1]\n",
    "use = list(use)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "T6xuWKfU7glP"
   },
   "outputs": [],
   "source": [
    "\n",
    "## Stolen from transformer code base without any noble intention.\n",
    "\n",
    "## Stolen from transformer code base without any noble intention.\n",
    "class Attention(nn.Module):\n",
    "    def __init__(self, feature_dim, step_dim, bias=True, **kwargs):\n",
    "        super(Attention, self).__init__(**kwargs)\n",
    "        \n",
    "        self.supports_masking = True\n",
    "\n",
    "        self.bias = bias\n",
    "        self.feature_dim = feature_dim\n",
    "        self.step_dim = step_dim\n",
    "        self.features_dim = 0\n",
    "        \n",
    "        weight = torch.zeros(feature_dim, 1)\n",
    "        nn.init.xavier_uniform_(weight)\n",
    "        self.weight = nn.Parameter(weight)\n",
    "        \n",
    "        if bias:\n",
    "            self.b = nn.Parameter(torch.zeros(step_dim))\n",
    "        \n",
    "    def forward(self, x, mask=None):\n",
    "        feature_dim = self.feature_dim\n",
    "        step_dim = self.step_dim\n",
    "\n",
    "        eij = torch.mm(\n",
    "            x.contiguous().view(-1, feature_dim), \n",
    "            self.weight\n",
    "        ).view(-1, step_dim)\n",
    "        \n",
    "        if self.bias:\n",
    "            eij = eij + self.b\n",
    "            \n",
    "        eij = torch.tanh(eij)\n",
    "        a = torch.exp(eij)\n",
    "        \n",
    "        if mask is not None:\n",
    "            a = a * mask\n",
    "\n",
    "        a = a / torch.sum(a, 1, keepdim=True) + 1e-10\n",
    "        \n",
    "        weighted_input = x.permute(1,0,2) * torch.unsqueeze(a, -1)\n",
    "        return torch.sum(weighted_input, 1)\n",
    "class cnnbert(BertPreTrainedModel):\n",
    "\n",
    "    def __init__(self, config,kernel_sizes,num_channels,use_shape):\n",
    "        super(cnnbert, self).__init__(config)\n",
    "        self.num_labels = config.num_labels\n",
    "        self.bert = BertModel(config)\n",
    "        self.dropout = nn.Dropout(0.3)\n",
    "        self.bn = nn.LayerNorm(768)\n",
    "        self.gelu=GELU()\n",
    "        self.att1=Attention(512,51)\n",
    "        self.att2=Attention(512,50)\n",
    "        self.att3=Attention(512,49)\n",
    "        self.att4=Attention(512,48)\n",
    "        self.att5=Attention(512,43)\n",
    "        self.softmax=nn.Softmax(dim=1)\n",
    "        self.pre_cnn=nn.Linear(1*sum(num_channels)+use_shape,1)\n",
    "        self.linear = nn.Linear(1*sum(num_channels)+use_shape,1*sum(num_channels)+use_shape)\n",
    "\n",
    "        self.ln_cnn=nn.LayerNorm(1*sum(num_channels))\n",
    "        self.wt=torch.nn.Parameter(torch.rand((13,1),dtype=torch.float32,device=torch.device('cuda'),requires_grad=True))\n",
    "        nn.init.xavier_normal_(self.wt)\n",
    "        self.pool = GlobalAVGPool1d()\n",
    "        self.convs = nn.ModuleList()\n",
    "        for c, k in zip(num_channels, kernel_sizes):\n",
    "          self.convs.append(nn.Conv1d(in_channels = 768,\n",
    "          out_channels = c,\n",
    "          kernel_size = k))\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        use,\n",
    "        input_ids=None,\n",
    "        attention_mask=None,\n",
    "        token_type_ids=None,\n",
    "        position_ids=None,\n",
    "        head_mask=None,\n",
    "        inputs_embeds=None,\n",
    "        labels=None,\n",
    "        \n",
    "    ):\n",
    "\n",
    "        outputs = self.bert(\n",
    "           \n",
    "            input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            token_type_ids=token_type_ids,\n",
    "            position_ids=position_ids,\n",
    "            head_mask=head_mask,\n",
    "            inputs_embeds=inputs_embeds,\n",
    "        )\n",
    "\n",
    "        w1=outputs[2] \n",
    "        batch_size1,len_seq1,e_s1=w1[1].size()\n",
    "        bert_output1=w1[0].to(device)\n",
    "        bert_output1=bert_output1.unsqueeze(1)\n",
    "        for i in range(1,13):\n",
    "          bert_output1=torch.cat((bert_output1,w1[i].to(device).unsqueeze(1)),dim=1)\n",
    "        bert_output1=bert_output1.view(batch_size1,13,-1)\n",
    "        bert_output1=bert_output1.permute(0,2,1)\n",
    "        bert_output1=torch.matmul(bert_output1,self.softmax((self.wt)))\n",
    "        bert_output1=bert_output1.view(batch_size1,len_seq1,e_s1)#下可接CNN或者att\n",
    "        bert_output1=self.bn(bert_output1)\n",
    "        bert_output1=bert_output1.permute(0, 2, 1)\n",
    "\n",
    "        bert_output1 = self.dropout(bert_output1)\n",
    "        '''conout1=self.att1(self.gelu(self.convs[0](bert_output1).permute(2,0,1)))\n",
    "        conout2=self.att2(self.gelu(self.convs[1](bert_output1).permute(2,0,1)))\n",
    "        conout3=self.att3(self.gelu(self.convs[2](bert_output1).permute(2,0,1)))\n",
    "        conout4=self.att4(self.gelu(self.convs[3](bert_output1).permute(2,0,1)))\n",
    "        conout5=self.att5(self.gelu(self.convs[4](bert_output1).permute(2,0,1)))\n",
    "        conout=torch.cat((conout1,conout2,conout3,conout4,conout5),dim=1)'''\n",
    "        encoding =torch.cat([self.pool(self.gelu(conv(bert_output1))).squeeze(-1) for conv in self.convs], dim=1)\n",
    "       \n",
    "        encoding=torch.cat((encoding,use),dim=1)\n",
    "        \n",
    "        logits = self.pre_cnn((encoding))\n",
    "        return logits "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "5r1L-rzm5lTY"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "PD1lhB935Yyk"
   },
   "outputs": [],
   "source": [
    "class GlobalAVGPool1d(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(GlobalAVGPool1d, self).__init__()\n",
    "    def forward(self, x):\n",
    "         # x shape: (batch_size, channel, seq_len)\n",
    "        return F.avg_pool1d(x, kernel_size=x.shape[2]) # shape: (batch_size, channel, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "OqwBAJlxBBY5"
   },
   "outputs": [],
   "source": [
    "class GELU(nn.Module):\n",
    "    \"\"\"\n",
    "    Paper Section 3.4, last paragraph notice that BERT used the GELU instead of RELU\n",
    "    \"\"\"\n",
    "\n",
    "    def forward(self, x):\n",
    "        return 0.5 * x * (1 + torch.tanh(math.sqrt(2 / math.pi) * (x + 0.044715 * torch.pow(x, 3))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "m4pAxPHAZUO2"
   },
   "outputs": [],
   "source": [
    "class EvalDataset(Dataset):\n",
    "  def __init__(self,train_idx,train_mask,train_segment,use,label=None):\n",
    "    self.train_idx = torch.tensor(train_idx,dtype=torch.int).long()\n",
    "    self.train_mask = torch.tensor(train_mask,dtype=torch.int).long()\n",
    "    self.train_segment = torch.tensor(train_segment,dtype=torch.int).long()\n",
    "    self.use = torch.tensor(use , dtype=torch.float32)\n",
    "    self.label = None\n",
    "    if label is not None:\n",
    "      self.label = torch.tensor(label,dtype=torch.float32)\n",
    "  def __len__(self):\n",
    "    return len(self.train_idx)\n",
    "  def __getitem__(self,item):\n",
    "    if self.label is not None:\n",
    "\n",
    "      output = {\n",
    "        'train_idx' : self.train_idx[item],\n",
    "        'train_mask' : self.train_mask[item],\n",
    "        'train_segment' :self.train_segment[item],\n",
    "        'use':self.use[item],\n",
    "        'label' : self.label[item]\n",
    "    }\n",
    "    else:\n",
    "      output = {\n",
    "        'train_idx' : self.train_idx[item],\n",
    "        'train_mask' : self.train_mask[item],\n",
    "        'use' : self.use[item],\n",
    "        'train_segment' :self.train_segment[item],\n",
    "      }\n",
    "    return {key: value for key, value in output.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "Fig-Sn7LaG2e"
   },
   "outputs": [],
   "source": [
    "bert_model_config = BERT_ROOT+'/bert_config.json'\n",
    "bert_config = BertConfig.from_json_file(bert_model_config)\n",
    "bert_config.num_labels = 1\n",
    "bert_config.output_hidden_states=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "p42xojCPZhax"
   },
   "outputs": [],
   "source": [
    "wdataset = EvalDataset(train_w20_idx,train_w20_mask,train_w20_segment,train_w20_lenths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "x3aW3oy-ZsH3"
   },
   "outputs": [],
   "source": [
    "pre_shape = len(train_w20_idx)\n",
    "pre_loader = DataLoader(wdataset,batch_size=128,shuffle=False)\n",
    "pred = np.zeros((pre_shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "7_gS4oOCbYGe"
   },
   "outputs": [],
   "source": [
    "device = torch.device('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "LzgF48EdbpHb"
   },
   "outputs": [],
   "source": [
    "def predict_model(model,predict_loader ,pre_shape,batch_size ,config=None):\n",
    "  ema.apply_shadow()\n",
    "  model.eval()\n",
    "  acc_lm = 0\n",
    "  acc_sent = 0\n",
    "  avg_loss = 0\n",
    "  pred = np.zeros((pre_shape))\n",
    "  with torch.no_grad():\n",
    "    for idx, batch in tqdm_notebook(enumerate(predict_loader),mininterval=2,desc='--Valing',leave=False):\n",
    "      input_ids = batch['train_idx'].to(device)\n",
    "      input_mask = batch['train_mask'].to(device)\n",
    "      input_segments = batch['train_segment'].to(device)\n",
    "      use = batch['use'].to(device)\n",
    "      output_train = model(use=use,input_ids = input_ids.long(),\n",
    "                              labels = None,\n",
    "                              attention_mask = input_mask,\n",
    "                              token_type_ids = input_segments,)\n",
    "      pred[idx*batch_size : (idx+1)*batch_size]=(torch.sigmoid(output_train.cpu().view(-1)))\n",
    "  ema.restore()\n",
    "  return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "V_NeSmAfaPxO"
   },
   "outputs": [],
   "source": [
    "for i in range(1,6):\n",
    "  kernel_sizes,nums_channels = [2,3,4,5,10], [512,512,512,512,512]\n",
    "  model = cnnbert.from_pretrained(BERT_ROOT,kernel_sizes=kernel_sizes,num_channels=nums_channels,use_shape=use_shape,config = bert_config)\n",
    "  model.to(device)\n",
    "  model.load_state_dict(torch.load('/content/drive/My Drive/dl/推荐评论/CNN/best_param_score_{}'.format(i)))\n",
    "  pred += predict_model(model,pre_loader ,pre_shape,128, config=None)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "oZ7MSlwmdowS"
   },
   "outputs": [],
   "source": [
    "(((pred/5)>0.5).astype(int)==1).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "RwK18-Qvc6XH"
   },
   "outputs": [],
   "source": [
    "torch.save(train_w20_idx,'/content/drive/My Drive/dl/推荐评论/CNN/w20_train_idx.pkl')\n",
    "torch.save(train_w20_mask,'/content/drive/My Drive/dl/推荐评论/CNN/w20_train_mask.pkl')\n",
    "torch.save(train_w20_segment,'/content/drive/My Drive/dl/推荐评论/CNN/w20_train_segment.pkl')\n",
    "torch.save(train_w20_lenths,'/content/drive/My Drive/dl/推荐评论/CNN/w20_train_lenth.pkl')\n",
    "torch.save(pred/5,'/content/drive/My Drive/dl/推荐评论/CNN/w20_train_label_notbin.pkl')\n",
    "torch.save(((pred/5)>0.5).astype(int),'/content/drive/My Drive/dl/推荐评论/CNN/w20_train_label_bin.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "YOkdldRSaooU"
   },
   "outputs": [],
   "source": [
    "(torch.load('/content/drive/My Drive/dl/推荐评论/CLS/label.pkl')==0).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TAkZn7aYgDG7"
   },
   "source": [
    "对等"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "R7gc0TiM3QIa"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "FD-Px3ef3S5A"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "weilabel.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
